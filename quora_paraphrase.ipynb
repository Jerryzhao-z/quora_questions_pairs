{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = './data/train.csv/train.csv'\n",
    "test_file = './data/test.csv/test.csv'\n",
    "\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 404290\n",
      "test dataset size: 2345796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = train.values[:,3:-1]\n",
    "train_label = train.values[:, -1]\n",
    "print (\"train dataset size: %d\" % len(train_data))\n",
    "\n",
    "test_data = test.values[:,1:]\n",
    "print (\"test dataset size: %d\" % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_questions = train_data.reshape((1,2*len(train_data)))\n",
    "test_questions = test_data.reshape((1,2*len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_words(words):\n",
    "    \"\"\"\n",
    "    :param words: a list of raw words.\n",
    "    :return: a list of words where each word is cleaned from special symbols.\n",
    "    \"\"\"\n",
    "    for w in words:\n",
    "        w = w.strip('\".\\'?)(:,!\\\\[]=/')\n",
    "        if w.endswith('\\'s'):\n",
    "            w = w[:len(w)-2]\n",
    "        if w is not '':\n",
    "            yield w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175283\n"
     ]
    }
   ],
   "source": [
    "words = set()\n",
    "for q in train_questions[0]:\n",
    "    words.update(clean_words(str(q).strip().lower().split(' ')))\n",
    "for q in test_questions[0]:\n",
    "    words.update(clean_words(str(q).strip().lower().split(' ')))\n",
    "words = list(words)\n",
    "words.sort()\n",
    "print (len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“unconscious”',\n",
       " '“under',\n",
       " '“uninterrupted”',\n",
       " '“unique',\n",
       " '“unit',\n",
       " '“united',\n",
       " '“universal”',\n",
       " '“unlimited',\n",
       " '“unmanageable”',\n",
       " '“unwanted',\n",
       " '“up',\n",
       " '“uri',\n",
       " '“us',\n",
       " '“usd',\n",
       " '“user',\n",
       " '“v=ultimate',\n",
       " '“vacuum”',\n",
       " '“vandalism”',\n",
       " '“vella',\n",
       " '“venga”',\n",
       " '“veni',\n",
       " '“very',\n",
       " '“view',\n",
       " '“vigorous',\n",
       " '“vinoth',\n",
       " '“voter',\n",
       " '“vt-x',\n",
       " '“vuforia',\n",
       " '“v”',\n",
       " '“waifu”',\n",
       " '“walk',\n",
       " '“walking”',\n",
       " '“warm',\n",
       " '“warmer',\n",
       " '“was”',\n",
       " '“watchlist”',\n",
       " '“wave',\n",
       " '“we',\n",
       " '“website',\n",
       " '“weird',\n",
       " '“welcome”',\n",
       " '“well',\n",
       " '“were”',\n",
       " '“wernicke”',\n",
       " '“westworld”',\n",
       " '“what',\n",
       " '“whatsapp”',\n",
       " '“what’s',\n",
       " '“wheedle”',\n",
       " '“where',\n",
       " '“which',\n",
       " '“while',\n",
       " '“whitewashing”',\n",
       " '“white”',\n",
       " '“who',\n",
       " '“why',\n",
       " '“why”',\n",
       " '“wifi-connection',\n",
       " '“wildest',\n",
       " '“will”',\n",
       " '“windows',\n",
       " '“windows.old”',\n",
       " '“winning”',\n",
       " '“win”',\n",
       " '“with',\n",
       " '“wolf',\n",
       " '“women',\n",
       " '“won”',\n",
       " '“workers',\n",
       " '“workplace”',\n",
       " '“world',\n",
       " '“world”',\n",
       " '“would',\n",
       " '“wussification”',\n",
       " '“x',\n",
       " '“x-bow”',\n",
       " '“x-men',\n",
       " '“xavier”',\n",
       " '“xeon”',\n",
       " '“xgboost”',\n",
       " '“xxx',\n",
       " '“x”',\n",
       " '“y',\n",
       " '“yaazha”',\n",
       " '“yahweh”',\n",
       " '“yankee”',\n",
       " '“yell”',\n",
       " '“yen”',\n",
       " '“yepme”',\n",
       " '“you',\n",
       " \"“you're\",\n",
       " '“your',\n",
       " '“yours”',\n",
       " '“your”',\n",
       " '“youthful',\n",
       " '“you’re',\n",
       " '“you”',\n",
       " '“yugam”',\n",
       " '“y”',\n",
       " '“zachte”',\n",
       " '“zacht”',\n",
       " '“zipautomobile”',\n",
       " '“zipcar”',\n",
       " '“zwaar”',\n",
       " '“zwakke”',\n",
       " '“zwak”',\n",
       " '“zware”',\n",
       " '“|”',\n",
       " '“±”',\n",
       " '“ذليل”',\n",
       " '“श्चश्चश्च”',\n",
       " '“”science””',\n",
       " '“”select””',\n",
       " '“…ease.”',\n",
       " '“不知天高地厚”',\n",
       " '“他得到第一名”',\n",
       " '“吃香喝辣”',\n",
       " '“天人”',\n",
       " '“如果不靠欺骗自己，还能靠什么支撑自己走下去”',\n",
       " '“我靠',\n",
       " '“星野拍摄”',\n",
       " '“有钱就是任性',\n",
       " '“杂”',\n",
       " '“杯具了”',\n",
       " '“毕竟”',\n",
       " '“清楚”',\n",
       " '“用中文的話',\n",
       " '“网络直播”in',\n",
       " '“能”and',\n",
       " '“能夠”',\n",
       " '“脑子进水”',\n",
       " '“脑袋抽筋”',\n",
       " '“膜”',\n",
       " '“蝶”',\n",
       " '“蝶々”',\n",
       " '“超市想诱导你购买不需要的东西”',\n",
       " '“高级黑”',\n",
       " '“북쪽앟관자키”',\n",
       " '”',\n",
       " '”dream',\n",
       " '”impostor',\n",
       " '”people',\n",
       " '”please',\n",
       " '”stalled',\n",
       " '”uncollapse”',\n",
       " '”内脏',\n",
       " '„all',\n",
       " '†',\n",
       " '•',\n",
       " '•how',\n",
       " '•what',\n",
       " '••',\n",
       " '…',\n",
       " '…(x+n',\n",
       " '…(x-n',\n",
       " '…+1',\n",
       " '…+100',\n",
       " '….+/-n',\n",
       " '….+dx+e=0',\n",
       " '….1800',\n",
       " '….please',\n",
       " '…advise',\n",
       " '…also',\n",
       " '…anand',\n",
       " '…and',\n",
       " '…any',\n",
       " '…anyone',\n",
       " '…are',\n",
       " '…but',\n",
       " '…can',\n",
       " '…do',\n",
       " '…elc',\n",
       " '…full',\n",
       " '…how',\n",
       " '…i',\n",
       " '…if',\n",
       " '…in',\n",
       " '…is',\n",
       " '…it',\n",
       " '…k',\n",
       " '…lalalalala',\n",
       " '…latest',\n",
       " '…log(log(log(2))…',\n",
       " '…my',\n",
       " '…or',\n",
       " '…please',\n",
       " '…pls',\n",
       " '…since',\n",
       " '…so',\n",
       " '…the',\n",
       " '…they',\n",
       " '…to',\n",
       " '…up',\n",
       " '…user',\n",
       " '…what',\n",
       " '…where',\n",
       " '…whether',\n",
       " '…who',\n",
       " '…}}}[/math',\n",
       " '…———…',\n",
       " '………',\n",
       " '…………',\n",
       " '\\u202a#\\u200ead\\u202c',\n",
       " '\\u202a#\\u200ebigdata\\u202c',\n",
       " '\\u202a#\\u200ebusiness\\u202c',\n",
       " '\\u202a#\\u200eclassified\\u202c',\n",
       " '\\u202a#\\u200edirectory\\u202c',\n",
       " '\\u202a#\\u200efree\\u202c',\n",
       " '\\u202a#\\u200ejobs\\u202c',\n",
       " '\\u202aare\\u202a',\n",
       " '\\u202acompany\\u202c',\n",
       " '\\u202adelhi\\u202c',\n",
       " '\\u202ambbs\\u202c',\n",
       " '\\u202a\\u200ebirth',\n",
       " '\\u202c',\n",
       " '\\u202d\\u202d',\n",
       " '′',\n",
       " '\\u2060\\u2060\\u2060what',\n",
       " '\\u2061〖x^n',\n",
       " '₩',\n",
       " '€',\n",
       " '€.can',\n",
       " '€/$/￡',\n",
       " '€1',\n",
       " '€1,600',\n",
       " '€100',\n",
       " '€10000',\n",
       " '€10b',\n",
       " '€10k',\n",
       " '€16.300',\n",
       " '€1950',\n",
       " '€2700',\n",
       " '€3211',\n",
       " '€4000',\n",
       " '€45000',\n",
       " '€50',\n",
       " '€500',\n",
       " '€50k',\n",
       " '€560',\n",
       " '€56k',\n",
       " '€570',\n",
       " '€600',\n",
       " '€65,000',\n",
       " '€6k',\n",
       " '€700',\n",
       " '€700-800',\n",
       " '€900',\n",
       " '₹',\n",
       " '₹1',\n",
       " '₹1,000',\n",
       " '₹10',\n",
       " '₹10,000',\n",
       " '₹10.how',\n",
       " '₹100',\n",
       " '₹1000',\n",
       " '₹1000/-',\n",
       " '₹10000',\n",
       " '₹100000',\n",
       " '₹10k',\n",
       " '₹12,000',\n",
       " '₹12000',\n",
       " '₹1298',\n",
       " '₹132000',\n",
       " '₹14k',\n",
       " '₹15,000',\n",
       " '₹1500',\n",
       " '₹15000',\n",
       " '₹1500per',\n",
       " '₹15k',\n",
       " '₹16',\n",
       " '₹1800',\n",
       " '₹1890',\n",
       " '₹199',\n",
       " '₹1k',\n",
       " '₹2',\n",
       " '₹2,85,000',\n",
       " '₹2.5',\n",
       " '₹20,000',\n",
       " '₹2000',\n",
       " '₹2000-',\n",
       " '₹20000',\n",
       " '₹20k',\n",
       " '₹22999',\n",
       " '₹23000',\n",
       " '₹24,900',\n",
       " '₹25',\n",
       " '₹2500',\n",
       " '₹25000',\n",
       " '₹25000-27000',\n",
       " '₹25k',\n",
       " '₹25k-30k',\n",
       " '₹28,990',\n",
       " '₹2k',\n",
       " '₹30,000',\n",
       " '₹300',\n",
       " '₹3000',\n",
       " '₹30000',\n",
       " '₹30k',\n",
       " '₹34k',\n",
       " '₹35',\n",
       " '₹35000',\n",
       " '₹4,00,000',\n",
       " '₹40,000',\n",
       " '₹40k',\n",
       " '₹40l',\n",
       " '₹50',\n",
       " '₹50,000',\n",
       " '₹50,000-₹55,000',\n",
       " '₹500',\n",
       " '₹500,₹1000',\n",
       " '₹500/-',\n",
       " '₹500/1000',\n",
       " '₹500/₹1000',\n",
       " '₹5000',\n",
       " '₹50000',\n",
       " '₹500000',\n",
       " '₹50k',\n",
       " '₹55',\n",
       " '₹5k',\n",
       " '₹5lpa',\n",
       " '₹60,000',\n",
       " '₹6000',\n",
       " '₹6000000',\n",
       " '₹65000',\n",
       " '₹70,000',\n",
       " '₹7000',\n",
       " '₹70000',\n",
       " '₹80,000',\n",
       " '₹8000',\n",
       " '₹8000-120000',\n",
       " '₹8000-₹10000',\n",
       " '₹85000',\n",
       " '₹90,000',\n",
       " '₹999',\n",
       " '℅',\n",
       " 'ℜ',\n",
       " 'ℝ²',\n",
       " '℞',\n",
       " '™',\n",
       " '→',\n",
       " '→1',\n",
       " '∀',\n",
       " '∀x',\n",
       " '∀x(q(x',\n",
       " '∀x¬(q(x',\n",
       " '∂y/∂x',\n",
       " '∂z/∂x[math',\n",
       " '∃x',\n",
       " '∃y',\n",
       " '∅',\n",
       " '∆',\n",
       " '∆abc',\n",
       " '∆aoe',\n",
       " '∆cdp',\n",
       " '∆cpq=20cm^2',\n",
       " '∆t',\n",
       " '∆u',\n",
       " '∆u=nc^v∆t',\n",
       " '∈',\n",
       " '∈z',\n",
       " '−',\n",
       " '−)∪',\n",
       " '−0.8i',\n",
       " '−1',\n",
       " '−100π',\n",
       " '−14',\n",
       " '−2',\n",
       " '−3',\n",
       " '−5',\n",
       " '−c',\n",
       " '−n',\n",
       " '−p',\n",
       " '∓',\n",
       " '∖',\n",
       " '∘c',\n",
       " '√',\n",
       " '√((√3',\n",
       " '√(-1',\n",
       " '√(1',\n",
       " '√(2/5',\n",
       " '√(75yz^2',\n",
       " '√(x+1',\n",
       " '√-1',\n",
       " '√-1*√-1',\n",
       " '√0',\n",
       " '√1+1/3',\n",
       " '√1+4x^2',\n",
       " '√1+√2+√3+√4+…+√n',\n",
       " '√1-x^2',\n",
       " '√11',\n",
       " '√17',\n",
       " '√2',\n",
       " '√2+√4+√8+√16+√32+√64+√128+…up',\n",
       " '√2,2√2',\n",
       " '√2/√5',\n",
       " '√3',\n",
       " '√3+1',\n",
       " '√3-1',\n",
       " '√3/2',\n",
       " '√3/4',\n",
       " '√32',\n",
       " '√3sinx−cosx−2ax+b',\n",
       " '√3−−2+b',\n",
       " '√4',\n",
       " '√42+√42+√42+',\n",
       " '√42-√42+√42-',\n",
       " '√42.√42.√42',\n",
       " '√5+1)]-√',\n",
       " '√5+2',\n",
       " '√5-2)}',\n",
       " '√5/3',\n",
       " '√556',\n",
       " '√7',\n",
       " '√9+',\n",
       " '√9+…',\n",
       " '√a+√b',\n",
       " '√a-√b÷√a+√b=1÷2',\n",
       " '√ab=√a',\n",
       " '√b',\n",
       " '√cosx',\n",
       " '√i+√-i',\n",
       " '√sinx',\n",
       " '√x',\n",
       " '√x+1/√x',\n",
       " '√y',\n",
       " '√√√√2',\n",
       " '∝',\n",
       " '∞',\n",
       " '∞}',\n",
       " '∞}{0}[/math',\n",
       " '∠a',\n",
       " '∠abc',\n",
       " '∠acb',\n",
       " '∠acp=120',\n",
       " '∠aic',\n",
       " '∠atb',\n",
       " '∠bac',\n",
       " '∠c',\n",
       " '∧¬p(x',\n",
       " '∨q(x',\n",
       " '∨∀x',\n",
       " '∩',\n",
       " '∩(a∪b',\n",
       " '∩a',\n",
       " '∩b',\n",
       " '∪',\n",
       " '∪(b-a',\n",
       " '∪)−',\n",
       " '∫',\n",
       " '∫(0-1',\n",
       " '∫(x+3)/√(4-x^2',\n",
       " '∫(x+5',\n",
       " '∫(x-1',\n",
       " '∫1+x',\n",
       " '∫2y*dy',\n",
       " '∫dt=∫dv',\n",
       " '∫f(x)dx',\n",
       " '∫π−π√1+x^2dx',\n",
       " '∴',\n",
       " '≈',\n",
       " '≜',\n",
       " '≠',\n",
       " '≡',\n",
       " '≡22(70',\n",
       " '≤',\n",
       " '≤42',\n",
       " '≥',\n",
       " '≥25/4',\n",
       " '≥rank(a',\n",
       " '⊂',\n",
       " '⊂b',\n",
       " '⊃',\n",
       " '⊆',\n",
       " '⊇',\n",
       " '⌈3n/2⌉−',\n",
       " '⏰time',\n",
       " '╥_╥',\n",
       " '◾teddy',\n",
       " '★',\n",
       " '☐',\n",
       " '☝',\n",
       " '☝february',\n",
       " '☝january',\n",
       " '☝july',\n",
       " '☝june',\n",
       " '☝march',\n",
       " '☝may',\n",
       " '☺',\n",
       " '♌️)leo',\n",
       " '♎️',\n",
       " '♑️)capricorn',\n",
       " '♒️)aquarius',\n",
       " '♥',\n",
       " '⚡1,2,6',\n",
       " '⚡2',\n",
       " '⚡4,6,2',\n",
       " '⚡amp',\n",
       " '⚡decode',\n",
       " '⚡first',\n",
       " \"⚡i'am\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-1000:-500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words are strange, needs to be cleaned\n",
    "1. other languages\n",
    "2. words start with symbols\n",
    "3. Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "word2index = dict()\n",
    "word2index.update(zip(words, itertools.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive train data:  149263\n",
      "negative train data:  255027\n"
     ]
    }
   ],
   "source": [
    "positive_train_data = [train_data[i] for i in range(len(train_data)) if train_label[i] == 1]\n",
    "negative_train_data = [train_data[i] for i in range(len(train_data)) if train_label[i] == 0]\n",
    "print (\"positive train data: \",len(positive_train_data))\n",
    "print (\"negative train data: \",len(negative_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How can I develop android app?' nan]\n",
      "['How can I create an Android app?' nan]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "y_positive_tuple = list()\n",
    "y_pair_positive_tuple = list()\n",
    "\n",
    "y_negative_tuple = list()\n",
    "y_pair_negative_tuple = list()\n",
    "\n",
    "line_ctr = itertools.count()\n",
    "for line in positive_train_data:\n",
    "    if isinstance(line[0], str)  and isinstance(line[1], str):\n",
    "        l = next(line_ctr)\n",
    "        y_positive_tuple.extend([(1, l, word2index[w]) for w in clean_words(line[0].rstrip().lower().split(' '))])\n",
    "        y_pair_positive_tuple.extend([(1, l, word2index[w]) for w in clean_words(line[1].rstrip().lower().split(' '))])\n",
    "    else:\n",
    "        print (line)\n",
    "y_positive_data, y_positive_row, y_positive_col = zip(*y_positive_tuple)\n",
    "y__pair_positive_data, y_pair_positive_row, y_pair_positive_col = zip(*y_pair_positive_tuple)\n",
    "\n",
    "M = next(line_ctr)\n",
    "O = len(word2index.keys())\n",
    "y_positive = sparse.csr_matrix((y_positive_data, (y_positive_row, y_positive_col)), shape=(M, O))\n",
    "y_pair_positive =  sparse.csr_matrix((y__pair_positive_data, (y_pair_positive_row, y_pair_positive_col)), shape=(M, O))\n",
    "\n",
    "\n",
    "line_ctr = itertools.count()\n",
    "\n",
    "for line in negative_train_data:\n",
    "    if isinstance(line[0], str)  and isinstance(line[1], str):\n",
    "        l = next(line_ctr)\n",
    "        y_negative_tuple.extend([(1, l, word2index[w]) for w in clean_words(line[0].rstrip().lower().split(' '))])\n",
    "        y_pair_negative_tuple.extend([(1, l, word2index[w]) for w in clean_words(line[1].rstrip().lower().split(' '))])\n",
    "    else:\n",
    "        print (line)\n",
    "        \n",
    "y_negative_data, y_negative_row, y_negative_col = zip(*y_negative_tuple)\n",
    "y__pair_negative_data, y_pair_negative_row, y_pair_negative_col = zip(*y_pair_negative_tuple)\n",
    "\n",
    "M = next(line_ctr)\n",
    "O = len(word2index.keys())\n",
    "y_negative = sparse.csr_matrix((y_negative_data, (y_negative_row, y_negative_col)), shape=(M, O))\n",
    "y_pair_negative =  sparse.csr_matrix((y__pair_negative_data, (y_pair_negative_row, y_pair_negative_col)), shape=(M, O))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_gradient_noise(t, stddev=1e-3, name=None):\n",
    "    \"\"\"\n",
    "    Adds gradient noise as described in http://arxiv.org/abs/1511.06807 [2].\n",
    "    The input Tensor `t` should be a gradient.\n",
    "    The output will be `t` + gaussian noise.\n",
    "    0.001 was said to be a good fixed value for memory networks [2].\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"add_gradient_noise\", [t, stddev]) as name:\n",
    "        t = tf.convert_to_tensor(t, name=\"t\")\n",
    "        gn = tf.random_normal(tf.shape(t), stddev=stddev)\n",
    "        return tf.add(t, gn, name=name)\n",
    "\n",
    "def normalize_vector(vector_to_normalize):\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(vector_to_normalize), 1, keep_dims=True))\n",
    "    normalized_vector = vector_to_normalize/norm\n",
    "    return normalized_vector\n",
    "\n",
    "def cosine(labels, predictions):\n",
    "    normalized_labels = normalize_vector(labels)\n",
    "    normalized_predictions = normalize_vector(predictions)\n",
    "    similarity = tf.matmul(normalized_labels, tf.transpose(normalized_predictions))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class quora_embedding(object):\n",
    "    def __init__(self, embedding_size, batch_size, vocabulary_size,sess):\n",
    "        self._embedding_size = embedding_size\n",
    "        self._batch_size = batch_size\n",
    "        self._vocabulary_size = vocabulary_size\n",
    "        self._lambda = 1.0\n",
    "        self._sess = sess\n",
    "        \n",
    "        self._opt = tf.train.AdadeltaOptimizer(1e-9)\n",
    "        \n",
    "        self.Wv = tf.Variable(initializer([15, O]), name=\"Wv\")\n",
    "        \n",
    "        self.y_positive = tf.placeholder(tf.float32, [None, self._vocabulary_size], name=\"y_positive\")\n",
    "        self.y_pair_positive = tf.placeholder(tf.float32, [None, self._vocabulary_size], name=\"y_pair_positive\")\n",
    "        self.y_negative = tf.placeholder(tf.float32, [None, self._vocabulary_size], name=\"y_negative\")\n",
    "        self.y_pair_negative = tf.placeholder(tf.float32, [None, self._vocabulary_size], name=\"y_pair_negative\")\n",
    "        \n",
    "        cosine_pair_positive_questions = self.cosine_similarity(self.y_positive, self.y_pair_positive)\n",
    "        cosine_pair_negative_questions = self.cosine_similarity(self.y_negative, self.y_pair_negative)\n",
    "        loss = tf.add(tf.subtract(self._lambda, cosine_pair_positive_questions), cosine_pair_negative_questions)\n",
    "    \n",
    "        self.cosine_pair_positive_questions = cosine_pair_positive_questions\n",
    "        self.cosine_pair_negative_questions = cosine_pair_negative_questions\n",
    "        \n",
    "        loss_sum = tf.reduce_sum(loss, name=\"loss_sum\")\n",
    "        self.loss= loss\n",
    "        self.loss_op = loss_sum\n",
    "        self.train_op = self._opt.minimize(self.loss_op)\n",
    "        \n",
    "        prediction = tf.sign(tf.nn.sigmoid(cosine_pair_positive_questions))\n",
    "        self.prediction_op = prediction\n",
    "        \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self._sess.run(init_op)\n",
    "        \n",
    "    def cosine_similarity(self, question1, question2):\n",
    "        q1 = tf.matmul(self.Wv,tf.transpose(question1))\n",
    "        q2 = tf.matmul(self.Wv,tf.transpose(question2))\n",
    "        cosine_sim =  cosine(tf.transpose(q1), tf.transpose(q2))\n",
    "        return tf.diag_part(cosine_sim)\n",
    "        \n",
    "    def batch_fit(self, y_positive, y_pair_positive, y_negative, y_pair_negative):\n",
    "        feed_dict = {self.y_positive: y_positive, self.y_pair_positive: y_pair_positive, self.y_negative:y_negative, self.y_pair_negative: y_pair_negative}\n",
    "        loss, loss_list, cosine_positive, cosine_negative, _ = self._sess.run([self.loss_op, self.loss, self.cosine_pair_positive_questions, self.cosine_pair_negative_questions, self.train_op], feed_dict=feed_dict)\n",
    "        return loss, loss_list, cosine_positive, cosine_negative\n",
    "    \n",
    "    def predict(self, y_positive, y_pair_positive):\n",
    "        feed_dict = {self.y_positive: y_positive, self.y_pair_positive: y_pair_positive}\n",
    "        pair = self._sess.run([self.prediction_op], feed_dict=feed_dict)\n",
    "        return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 percentage:  64 / 149263  average cost:  0.843720257282  total cost:  53.9981\n",
      "Epoch:  1 percentage:  128 / 149263  average cost:  0.798480153084  total cost:  51.1027\n",
      "Epoch:  1 percentage:  192 / 149263  average cost:  0.854834794998  total cost:  54.7094\n",
      "Epoch:  1 percentage:  256 / 149263  average cost:  0.841115117073  total cost:  53.8314\n",
      "Epoch:  1 percentage:  320 / 149263  average cost:  0.739943385124  total cost:  47.3564\n",
      "Epoch:  1 percentage:  384 / 149263  average cost:  0.751837730408  total cost:  48.1176\n",
      "Epoch:  1 percentage:  448 / 149263  average cost:  0.858372092247  total cost:  54.9358\n",
      "Epoch:  1 percentage:  512 / 149263  average cost:  0.742621541023  total cost:  47.5278\n",
      "Epoch:  1 percentage:  576 / 149263  average cost:  0.782336235046  total cost:  50.0695\n",
      "Epoch:  1 percentage:  640 / 149263  average cost:  0.704456090927  total cost:  45.0852\n",
      "Epoch:  1 percentage:  704 / 149263  average cost:  0.854189693928  total cost:  54.6681\n",
      "Epoch:  1 percentage:  768 / 149263  average cost:  0.811494350433  total cost:  51.9356\n",
      "Epoch:  1 percentage:  832 / 149263  average cost:  0.75368475914  total cost:  48.2358\n",
      "Epoch:  1 percentage:  896 / 149263  average cost:  0.856253266335  total cost:  54.8002\n",
      "Epoch:  1 percentage:  960 / 149263  average cost:  0.828772068024  total cost:  53.0414\n",
      "Epoch:  1 percentage:  1024 / 149263  average cost:  0.819456100464  total cost:  52.4452\n",
      "Epoch:  1 percentage:  1088 / 149263  average cost:  0.789965510368  total cost:  50.5578\n",
      "Epoch:  1 percentage:  1152 / 149263  average cost:  0.833085894585  total cost:  53.3175\n",
      "Epoch:  1 percentage:  1216 / 149263  average cost:  0.88751488924  total cost:  56.801\n",
      "Epoch:  1 percentage:  1280 / 149263  average cost:  0.870816886425  total cost:  55.7323\n",
      "Epoch:  1 percentage:  1344 / 149263  average cost:  0.779364943504  total cost:  49.8794\n",
      "Epoch:  1 percentage:  1408 / 149263  average cost:  0.793175935745  total cost:  50.7633\n",
      "Epoch:  1 percentage:  1472 / 149263  average cost:  0.895349621773  total cost:  57.3024\n",
      "Epoch:  1 percentage:  1536 / 149263  average cost:  0.809031903744  total cost:  51.778\n",
      "Epoch:  1 percentage:  1600 / 149263  average cost:  0.787213742733  total cost:  50.3817\n",
      "Epoch:  1 percentage:  1664 / 149263  average cost:  0.870450019836  total cost:  55.7088\n",
      "Epoch:  1 percentage:  1728 / 149263  average cost:  0.82954788208  total cost:  53.0911\n",
      "Epoch:  1 percentage:  1792 / 149263  average cost:  0.804622530937  total cost:  51.4958\n",
      "Epoch:  1 percentage:  1856 / 149263  average cost:  0.947994470596  total cost:  60.6716\n",
      "Epoch:  1 percentage:  1920 / 149263  average cost:  0.79191660881  total cost:  50.6827\n",
      "Epoch:  1 percentage:  1984 / 149263  average cost:  0.834622740746  total cost:  53.4159\n",
      "Epoch:  1 percentage:  2048 / 149263  average cost:  0.90948086977  total cost:  58.2068\n",
      "Epoch:  1 percentage:  2112 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2176 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2240 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2304 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2368 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2432 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2496 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2560 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2624 / 149263  average cost:  nan  total cost:  nan\n",
      "Epoch:  1 percentage:  2688 / 149263  average cost:  nan  total cost:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-553c458859a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_negative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mq4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pair_negative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtotal_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-ee49c06f8e39>\u001b[0m in \u001b[0;36mbatch_fit\u001b[0;34m(self, y_positive, y_pair_positive, y_negative, y_pair_negative)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pair_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pair_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_positive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pair_positive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_pair_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_negative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pair_negative\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_pair_negative\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_pair_positive_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_pair_negative_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_size = 15\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "batches = zip(range(0, len(positive_train_data)-batch_size, batch_size), range(batch_size, len(positive_train_data), batch_size))\n",
    "batches = [(start, end) for start, end in batches]\n",
    "\n",
    "negative_batches = zip(range(0, len(negative_train_data)-batch_size, batch_size), range(batch_size, len(negative_train_data), batch_size))\n",
    "negative_batches = [(start, end) for start, end in negative_batches]\n",
    "\n",
    "initializer = tf.random_normal_initializer(mean=0, stddev=1/embedding_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = quora_embedding(embedding_size, batch_size, O, sess)\n",
    "    \n",
    "    for i in range(1, epochs):\n",
    "        # np.random.shuffle(batches)\n",
    "        # np.random.shuffle(negative_batches)\n",
    "        \n",
    "        nombre = 0\n",
    "        total_cost = 0.0\n",
    "        for (start, end) in batches:\n",
    "            nombre += end-start\n",
    "            q1 = y_positive[start: end].astype(np.float32)\n",
    "            q2 = y_pair_positive[start: end].astype(np.float32)\n",
    "            q3 = y_negative[start: end].astype(np.float32)\n",
    "            q4 = y_pair_negative[start: end].astype(np.float32)\n",
    "            cost, cost_list, cosine_positive, cosine_negative = model.batch_fit(q1.todense(), q2.todense(), q3.todense(), q4.todense())\n",
    "            total_cost += cost\n",
    "            if cost == 0:\n",
    "                print (start, '/', end)\n",
    "                print (cost_list)\n",
    "                print (cosine_positive)\n",
    "                print (cosine_negative)\n",
    "                break\n",
    "            print (\"Epoch: \", i, \"percentage: \", nombre,\"/\", len(positive_train_data), \" average cost: \", cost/batch_size, \" total cost: \", cost)\n",
    "            \n",
    "        print('-----------------------')\n",
    "        print('Epoch', i)\n",
    "        print('Total Cost:', total_cost)\n",
    "        print('average cost:', total_cost/nombre)\n",
    "        print('-----------------------')\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
